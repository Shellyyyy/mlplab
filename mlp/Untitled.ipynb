{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28df0534ed2f42db8a2ad67a0a2bb20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_epochs', max=5, min=1), IntSlider(value=200, descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from mlp.data_providers import CCPPDataProvider\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "def error(outputs, targets):\n",
    "    Error = np.dot((outputs-targets).T,outputs-targets)\n",
    "    if Error.shape==():\n",
    "        totalerror = Error\n",
    "    else:\n",
    "        totalerror = 0\n",
    "        for i in range(Error.shape[0]):\n",
    "            totalerror += Error[i,i]\n",
    "    return totalerror/(2*outputs.shape[0])\n",
    "    \n",
    "def fprop(inputs, weights, biases):\n",
    "    return np.dot(inputs,weights.T) + biases  \n",
    "\n",
    "def error_grad(outputs, targets):\n",
    "    return (outputs-targets)/outputs.shape[0]\n",
    "\n",
    "def grads_wrt_params(inputs, grads_wrt_outputs):\n",
    "    return (grads_wrt_outputs.T @ inputs,grads_wrt_outputs.sum(axis=0))\n",
    "\n",
    "def setup_figure():\n",
    "    # create figure and axes\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    ax1 = fig.add_axes([0., 0., 0.5, 1.], projection='3d')\n",
    "    ax2 = fig.add_axes([0.6, 0.1, 0.4, 0.8])\n",
    "    # set axes properties\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    ax2.set_yscale('log')\n",
    "    ax1.set_xlim((-2, 2))\n",
    "    ax1.set_ylim((-2, 2))\n",
    "    ax1.set_zlim((-2, 2))\n",
    "    #set axes labels and title\n",
    "    ax1.set_title('Parameter trajectories over training')\n",
    "    ax1.set_xlabel('Weight 1')\n",
    "    ax1.set_ylabel('Weight 2')\n",
    "    ax1.set_zlabel('Bias')\n",
    "    ax2.set_title('Batch errors over training')\n",
    "    ax2.set_xlabel('Batch update number')\n",
    "    ax2.set_ylabel('Batch error')\n",
    "    return fig, ax1, ax2\n",
    "\n",
    "def visualise_training(n_epochs=1, batch_size=200, log_lr=-1., n_inits=5,\n",
    "                       w_scale=1., b_scale=1., elev=30., azim=0.):\n",
    "    fig, ax1, ax2 = setup_figure()\n",
    "    # create seeded random number generator\n",
    "    rng = np.random.RandomState(1234)\n",
    "    # create data provider\n",
    "    data_provider = CCPPDataProvider(\n",
    "        input_dims=[0, 1],\n",
    "        batch_size=batch_size, \n",
    "        shuffle_order=False,\n",
    "    )\n",
    "    learning_rate = 10 ** log_lr\n",
    "    n_batches = data_provider.num_batches\n",
    "    weights_traj = np.empty((n_inits, n_epochs * n_batches + 1, 1, 2))\n",
    "    biases_traj = np.empty((n_inits, n_epochs * n_batches + 1, 1))\n",
    "    errors_traj = np.empty((n_inits, n_epochs * n_batches))\n",
    "    # randomly initialise parameters\n",
    "    weights = rng.uniform(-w_scale, w_scale, (n_inits, 1, 2))\n",
    "    biases = rng.uniform(-b_scale, b_scale, (n_inits, 1))\n",
    "    # store initial parameters\n",
    "    weights_traj[:, 0] = weights\n",
    "    biases_traj[:, 0] = biases\n",
    "    # iterate across different initialisations\n",
    "    for i in range(n_inits):\n",
    "        # iterate across epochs\n",
    "        for e in range(n_epochs):\n",
    "            # iterate across batches\n",
    "            for b, (inputs, targets) in enumerate(data_provider):\n",
    "                outputs = fprop(inputs, weights[i], biases[i])\n",
    "                errors_traj[i, e * n_batches + b] = error(outputs, targets)\n",
    "                grad_wrt_outputs = error_grad(outputs, targets)\n",
    "                weights_grad, biases_grad = grads_wrt_params(inputs, grad_wrt_outputs)\n",
    "                weights[i] -= learning_rate * weights_grad\n",
    "                biases[i] -= learning_rate * biases_grad\n",
    "                weights_traj[i, e * n_batches + b + 1] = weights[i]\n",
    "                biases_traj[i, e * n_batches + b + 1] = biases[i]\n",
    "    # choose a different color for each trajectory\n",
    "    colors = plt.cm.jet(np.linspace(0, 1, n_inits))\n",
    "    # plot all trajectories\n",
    "    for i in range(n_inits):\n",
    "        lines_1 = ax1.plot(\n",
    "            weights_traj[i, :, 0, 0], \n",
    "            weights_traj[i, :, 0, 1], \n",
    "            biases_traj[i, :, 0], \n",
    "            '-', c=colors[i], lw=2)\n",
    "        lines_2 = ax2.plot(\n",
    "            np.arange(n_batches * n_epochs),\n",
    "            errors_traj[i],\n",
    "            c=colors[i]\n",
    "        )\n",
    "    ax1.view_init(elev, azim)\n",
    "    plt.show()\n",
    "\n",
    "w = interact(\n",
    "    visualise_training,\n",
    "    elev=(-90, 90, 2),\n",
    "    azim=(-180, 180, 2), \n",
    "    n_epochs=(1, 5), \n",
    "    batch_size=(100, 1000, 100),\n",
    "    log_lr=(-3., 1.),\n",
    "    w_scale=(0., 2.),\n",
    "    b_scale=(0., 2.),\n",
    "    n_inits=(1, 10)\n",
    ")\n",
    "\n",
    "for child in w.widget.children:\n",
    "    child.layout.width = '100%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
